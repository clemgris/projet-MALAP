{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fcf9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39e5b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "subm = pd.read_csv('../input/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b364fbaf",
   "metadata": {},
   "source": [
    "### Looking at the data\n",
    "The training data contains a row per comment, with an id, the text of the comment, and 6 different labels that we'll try to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e18493",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e799079",
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = train.comment_text.str.len()\n",
    "lens.mean(), lens.std(), lens.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2922f4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lens.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc7c859",
   "metadata": {},
   "source": [
    "We'll create a list of all the labels to predict, and we'll also create a 'none' label so we can see how many comments have no labels. We can then summarize the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2aaecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "train['none'] = 1-train[label_cols].max(axis=1)\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699f05b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train),len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355b60c7",
   "metadata": {},
   "source": [
    "There are a few empty comments that we need to get rid of, otherwise sklearn will complain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc6c280",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMENT = 'comment_text'\n",
    "train[COMMENT].fillna(\"unknown\", inplace=True)\n",
    "test[COMMENT].fillna(\"unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2b5755",
   "metadata": {},
   "source": [
    "### Building the model\n",
    "We'll start by creating a bag of words representation, as a term document matrix. We'll use ngrams, as suggested in the NBSVM paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381776df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string\n",
    "re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "def tokenize(s): return re_tok.sub(r' \\1 ', s).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8d1cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = train.shape[0]\n",
    "vec = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n",
    "               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1 )\n",
    "trn_term_doc = vec.fit_transform(train[COMMENT])\n",
    "test_term_doc = vec.transform(test[COMMENT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b6128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_term_doc, test_term_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4666edc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pr(y_i, y):\n",
    "    p = x[y==y_i].sum(0)\n",
    "    return (p+1) / ((y==y_i).sum()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94aed4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = trn_term_doc\n",
    "test_x = test_term_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0175c03c",
   "metadata": {},
   "source": [
    "Fit a model for one dependent at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f5d6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mdl(y):\n",
    "    y = y.values\n",
    "    r = np.log(pr(1,y) / pr(0,y))\n",
    "    m = LogisticRegression(C=4, dual=True)\n",
    "    x_nb = x.multiply(r)\n",
    "    return m.fit(x_nb, y), r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b012eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.zeros((len(test), len(label_cols)))\n",
    "\n",
    "for i, j in enumerate(label_cols):\n",
    "    print('fit', j)\n",
    "    m,r = get_mdl(train[j])\n",
    "    preds[:,i] = m.predict_proba(test_x.multiply(r))[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c68564b",
   "metadata": {},
   "source": [
    "And finally, create the submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cf6e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "submid = pd.DataFrame({'id': subm[\"id\"]})\n",
    "submission = pd.concat([submid, pd.DataFrame(preds, columns = label_cols)], axis=1)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
